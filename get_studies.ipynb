{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['metadata', 'data', 'criteria', '__index_level_0__'],\n",
      "        num_rows: 31840\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['metadata', 'data', 'criteria', '__index_level_0__'],\n",
      "        num_rows: 3980\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['metadata', 'data', 'criteria', '__index_level_0__'],\n",
      "        num_rows: 3981\n",
      "    })\n",
      "})\n",
      "{'metadata': '{\\n\"NCT_ID\" : \"NCT00933777\",\\n\"Brief_Title\" : \"SORAVE - Sorafenib and Everolimus in Solid Tumors\",\\n\\n\"Official_title\" : \"SORAVE-Sorafenib and Everolimus in Solid Tumors. A Phase I Clinical Trial to Evaluate the Safety of Combined Sorafenib and Everolimus Treatment in Patients With Relapsed Solid Tumors\",\\n\\n\"Conditions\" : [Unspecified Adult Solid Tumor, Protocol Specific, Non-Small Cell Lung Cancer],\\n\\n\"Interventions\" : [Drug: Combination of sorafenib and everolimus],\\n\\n\"Location_Countries\" : [Germany],\\n\\n\"Study_Design\" : {\\n\"Study_Type\" : \"INTERVENTIONAL\",\\n\"Phase\" : [PHASE1],\\n\"Primary_Purpose\" : \"TREATMENT\",\\n\"Allocation\" : \"NA\",\\n\"Interventional Model\" : \"SINGLE_GROUP\",\\n\"Masking\" : \"NONE\"\\n }\\n}', 'data': 'Study Description \\nBrief Summary \\nDose finding part: A phase I clinical trial to evaluate the safety of combined sorafenib and everolimus treatment in patients with relapsed solid tumors (finished).\\n\\nExtension part:Treatment of non-small cell lung cancer (NSCLC) with KRAS mutation after ≥ 1st relapse (recruiting)\\n\\nDetailed Description \\nDose finding part: Patients will be recruited to receive combination of defined sorafenib dose (2x400mg) with increasing dose of everolimus (2.5mg, 5mg, 7.5mg, 10mg). There will be a run-in phase of 14 days of everolimus followed by combination sorafenib+everolimus starting from day 15. The combination will be continued as long as it is tolerated by the patient and the patient benefits from the treatment according to RECIST criteria. The maximal tolerated dose will be establish in 3+3 design. Patients will be recruited sequentially at least 14 days apart. The next dose level according to 3+3 design will be initiated if all patients on the previous dose level reach day 29.\\n\\nExtension part: Patients will be treated with a dose of 7,5 mg Everolimus for 14 days (run-in phase) and sorafenib 2x 400 mg until progression\\n\\nIntervention \\n- DRUG : Combination of sorafenib and everolimus \\n\\t- Dose finding: Treatment with defined dose of sorafenib of 2x400 mg with increasing dose of everolimus (2.5 mg, 5 mg, 7.5 mg, 10 mg) Extension: Treatment with defined dose of sorafenib of 2x400 mg with everolimus 7.5 mg\\n\\t- Nexavar, RAD001', 'criteria': 'Inclusion Criteria:\\n\\n* Patients with solid tumors relapsed after and/or refractory to standard therapy (dose finding part), KRAS mutated NSCLC patients after >= 1st relapse for the extension phase\\n* >= 18 years\\n* Performance status ECOG 0 <= age <= 2\\n* Life expectancy of at least 12 weeks\\n* Subjects with at least one measurable (CT or MRI) lesion\\n* Adequate bone marrow, liver and renal function as assessed by the following laboratory requirements to be conducted within 7 days prior to screening:\\n\\n  * Hemoglobin >= 9.0 g/dL\\n  * Absolute neutrophil count (ANC) >= 1,500 /mm3\\n  * Platelet count >= 100 000/µL\\n  * Total bilirubin <= 1,5x upper limit of normal (ULN)\\n  * ALT and AST <= 2,5x ULN (<= 5x ULN for patients with liver involvement)\\n  * Alkaline phosphatase < 4x ULN\\n  * Potassium within normal limits (WNL) or correctable with supplements\\n  * Total calcium (corrected for serum albumin) WNL or correctable with supplements\\n  * Magnesium WNL or correctable with supplements\\n  * PT-INR/PTT < 1.5 x ULN [Patients who are being therapeutically anticoagulated with an agent such as coumadin or heparin will be allowed to participate provided that no prior evidence of underlying abnormality in these parameters exists]\\n  * Serum creatinine <= 1.5 x upper limit of normal or creatinine clearance (CrCl) >= 50 ml/min calculated by either Cockcroft-Gault or by 24 hours urine collection\\n* More than 14 days since previous systemic therapy, radiotherapy and surgery\\n* Negative urine or serum HCG in women of childbearing potential\\n* Signed and dated informed consent before the start of specific protocol procedures\\n\\nExclusion Criteria:\\n\\n* Squamous cell carcinoma histology in non-small cell lung cancer\\n* History of cardiac disease: congestive heart failure > NYHA class 2; active Coronary Arterial Disease (CAD), (MI more than 6 months prior to study entry is allowed); cardiac arrythmias requiring anti-arrythmic therapy (except, when controlled by beta blockers or digoxin) or uncontrolled hypertension; for Extension phase: Long QT-Syndrome\\n* Active skin, mucosa, ocular or GI disorders of grade > 1\\n* Uncontrolled diabetes\\n* >= grade 3 hypercholesterolemia/hypertriglyceridemia or >= grade 2 hypercholesterolemia / hypertriglyceridemia with history of CAD (despite lipid lowering treatment if given)\\n* Impairment of gastrointestinal function or gastrointestinal disease that may significantly alter the absorption of everolimus and sorafenib (e.g. ulcerative disease, uncontrolled nausea, vomiting, diarrhea, malabsorption syndrome or small bowel resection)\\n* History of HIV infection or previously sero-positive for the virus\\n* History of Hepatitis B or/and C or previously sero-positive for the Hepatitis B or/and C virus\\n* Leptomeningeal or uncontrolled brain metastases, including patients who continue to require glucocorticoids or intrathecal chemotherapy for brain or leptomeningeal metastases (documented by lumbar puncture)\\n* Treatment with any other investigational drugs within the previous 14 days\\n* Patients with seizure disorder requiring anti-epileptics\\n* History of organ allograft\\n* Patients with evidence or history of bleeding diathesis\\n* Patients undergoing renal dialysis\\n* Previous treatment with mTOR inhibitors and/or known hypersensitivity to mTOR inhibitors\\n* Past or current history of cancer other than the entry diagnosis EXCEPT cervical carcinoma in situ, treated basal cell carcinoma, superficial bladder tumors [Ta, Tis & T1] or any cancer curatively treated > 3 years prior to study entry\\n* Any person being in an institution on assignment of the respective authority\\n* Any medical, mental or psychological condition which in the opinion of the investigator would not permit the patient to complete the study or understand the patient information\\n* Women who are pregnant or breast feeding, or women who are able to conceive and unwilling to practice an effective method of birth control (safe hormonal methods or/and barrier contraception) during study and 2 months after the last study drug intake\\n\\nFor Extension part:\\n\\n* Patients with medication that prolongs QTc and cannot be withdrawn (if the QTc prolonging medication is withdrawn - there must be a time interval of at least 7 days before starting treatment with sorafenib, in case of amiodarone the time interval is at least 90 days)\\n* Testing for Hepatitis B is mandatory\"Sex\" : ALL\\n\"Ages\" : \\n- Minimum Age : 18 Years\\n\\nAccepts Healthy Volunteers: No\\n', '__index_level_0__': 31648}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ravis_dataset = load_dataset(\"ravistech/clinical-trial-llm-cancer-restructure\")\n",
    "\n",
    "print(ravis_dataset)\n",
    "print(ravis_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def fix_invalid_json(input_str):\n",
    "    ## add double quotes around elements inside square brackets if not already quoted\n",
    "    fixed_str = re.sub(r'(?<=\\[)([^\\[\\],]+)(?=\\])', lambda x: '\"' + x.group(0).strip() + '\"', input_str)\n",
    "    \n",
    "    ## add double quotes around words in Conditions and Interventions\n",
    "    fixed_str = re.sub(r'(?<=\\[)([^\\\"\\]]+?)(?=\\])', lambda x: '\"' + x.group(0).strip().replace(\", \", '\", \"') + '\"', fixed_str)\n",
    "    \n",
    "    ## fix key-value pairs inside Interventions\n",
    "    fixed_str = re.sub(r'\"([A-Za-z]+): ([A-Za-z0-9\\s]+)\"', r'\"\\1: \\2\"', fixed_str)\n",
    "    \n",
    "    # fix dictionary keys\n",
    "    fixed_str = re.sub(r'(?<!\")(\\b[A-Za-z_]+\\b)(?=\\s*:)', r'\"\\1\"', fixed_str)\n",
    "    \n",
    "    return fixed_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: json_repair in /home/swiss/miniconda3/envs/ML/lib/python3.11/site-packages (0.30.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swiss/miniconda3/envs/ML/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 750/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 1500/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 2250/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 3000/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 3750/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 4500/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 5250/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 6000/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 6750/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 7500/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 8250/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 9000/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 9750/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 10500/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 11250/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 12000/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 12750/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 13500/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 14250/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 15000/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 15750/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 16500/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 17250/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 18000/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 18750/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 19500/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 20250/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 21000/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 21750/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 22500/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 23250/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 24000/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 24750/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 25500/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 26250/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 27000/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 27750/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 28500/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 29250/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 30000/31840\n",
      "Processed and added batch of 750 studies.\n",
      "Processed 750 studies. 30750/31840\n",
      "Processed and added batch of 696 studies.\n",
      "Embedding and storing complete!\n"
     ]
    }
   ],
   "source": [
    "!pip install json_repair\n",
    "import chromadb\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import json_repair\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from unidecode import unidecode\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"./clinical_trials_chroma\")\n",
    "model = SentenceTransformer(\"malteos/scincl\")\n",
    "collection = client.get_or_create_collection(\"clinical_trials_studies\")\n",
    "\n",
    "ravis_dataset = load_dataset(\"ravistech/clinical-trial-llm-cancer-restructure\")\n",
    "\n",
    "def embed_studies_from_dataset(dataset, batch_size=32):\n",
    "    batch_texts = []       \n",
    "    batch_metadata = []    \n",
    "    batch_documents = []   \n",
    "    batch_ids = []         \n",
    "    index = 1\n",
    "    length = len(dataset['train'])\n",
    "    \n",
    "    for study in dataset['train']:\n",
    "            metadata = json_repair.loads(fix_invalid_json(study['metadata']))\n",
    "            official_title = metadata.get('Official_title', '')\n",
    "            detailed_description = study.get('data', '')\n",
    "\n",
    "            # Skip if no valid officialTitle or detailedDescription\n",
    "            if not official_title or not detailed_description:\n",
    "                continue\n",
    "            concatenated_text = unidecode(f\"{official_title} [SEP] {detailed_description}\")\n",
    "            batch_texts.append(concatenated_text)\n",
    "            batch_metadata.append({\n",
    "                \"nctId\": metadata.get(\"NCT_ID\", \"unknown\"),\n",
    "                \"officialTitle\": official_title,\n",
    "                \"detailedDescription\": detailed_description,\n",
    "                \"jsonMetadata\": json.dumps(metadata, ensure_ascii=True)\n",
    "            })\n",
    "            batch_documents.append(json.dumps({\n",
    "                \"metadata\": metadata,\n",
    "                \"description\": study.get('data', ''),\n",
    "                \"criteria\": study.get('criteria', '')\n",
    "                },ensure_ascii=True))\n",
    "            batch_ids.append(metadata.get(\"NCT_ID\", \"unknown\"))\n",
    "\n",
    "            # When batch size is reached, process the batch\n",
    "            if len(batch_texts) == batch_size:\n",
    "                process_batch(batch_texts, batch_documents, batch_ids, batch_metadata)\n",
    "                print(f\"Processed {len(batch_texts)} studies. {index}/{length}\")\n",
    "                # Clear the batches\n",
    "                batch_texts.clear()\n",
    "                batch_documents.clear()\n",
    "                batch_metadata.clear()\n",
    "                batch_ids.clear()\n",
    "            index += 1\n",
    "\n",
    "    if batch_texts:\n",
    "        process_batch(batch_texts, batch_documents, batch_ids, batch_metadata)\n",
    "\n",
    "def process_batch(texts, documents, ids, metadatas):\n",
    "    embeddings = model.encode(texts, batch_size=len(texts))\n",
    "    collection.add(\n",
    "        embeddings=embeddings,\n",
    "        documents=documents,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids\n",
    "    )\n",
    "    print(f\"Processed and added batch of {len(texts)} studies.\")\n",
    "\n",
    "# adjust batch_size to fit in your gpu memory\n",
    "embed_studies_from_dataset(ravis_dataset, batch_size=750)\n",
    "print(\"Embedding and storing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
